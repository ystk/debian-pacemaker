[appendix]

== Installing == 

=== Installing the Software ===

Most major Linux distributions have pacemaker packages in their standard
package repositories, or the software can be built from source code.
See the http://clusterlabs.org/wiki/Install[Install wiki page] for details.

See <<q-messaging-layer,Which Messaging Layer Should I Choose?>>
for information about choosing a messaging layer.

=== Enabling Pacemaker ===

==== Enabling Pacemaker For Corosync 2._x_ ====

High-level cluster management tools are available that can configure
corosync for you. This document focuses on the lower-level details
if you want to configure corosync yourself.

Corosync configuration is normally located in
+/etc/corosync/corosync.conf+.

.Corosync 2._x_ configuration file for two nodes *myhost1* and *myhost2*
====
----
totem {
version: 2
secauth: off
cluster_name: mycluster
transport: udpu
}

nodelist {
  node {
        ring0_addr: myhost1
        nodeid: 1
       }
  node {
        ring0_addr: myhost2
        nodeid: 2
       }
}

quorum {
provider: corosync_votequorum
two_node: 1
}

logging {
to_syslog: yes
}
----
====

.Corosync 2._x_ configuration file for three nodes *myhost1*, *myhost2* and *myhost3*
====
----
totem {
version: 2
secauth: off
cluster_name: mycluster
transport: udpu
}

nodelist {
  node {
        ring0_addr: myhost1
        nodeid: 1
       }
  node {
        ring0_addr: myhost2
        nodeid: 2
       }
  node {
        ring0_addr: myhost3
        nodeid: 3
       }
}

quorum {
provider: corosync_votequorum

}

logging {
to_syslog: yes
}
----
====

In the above examples, the +totem+ section defines what protocol version and
options (including encryption) to use,
footnote:[
Please consult the Corosync website (http://www.corosync.org/) and
documentation for details on enabling encryption and peer authentication for
the cluster.
]
and gives the cluster a unique name (+mycluster+ in these examples).

The +node+ section lists the nodes in this cluster. (See <<s-node-name>>
for how this affects pacemaker.)

The +quorum+ section defines how the cluster uses quorum.
The important thing is that two-node clusters must be handled specially,
so +two_node: 1+ must be defined for two-node clusters (and only for two-node
clusters).

The +logging+ section should be self-explanatory.

==== Enabling Pacemaker For Corosync 1._x_ ====

.Corosync 1._x_ configuration file for a cluster with all nodes on the +192.0.2.0/24+ network
====
[source,XML]
-------
  totem {
      version: 2
      secauth: off
      threads: 0
      interface {
          ringnumber: 0
          bindnetaddr: 192.0.2.0
          mcastaddr: 239.255.1.1
          mcastport: 1234
      }
  }
  logging {
      fileline: off
      to_syslog: yes
      syslog_facility: daemon
  }
  amf {
      mode: disabled
  }
-------
====

With corosync 1._x_, the +totem+ section contains the protocol version and
options as with 2._x_. However, nodes are also listed here,
in the +interface+ section. The +bindnetaddr+ option is usually the _network_
address, thus allowing the same configuration file to be used on all nodes.
IPv4 or IPv6 addresses can be used with corosync.

The +amf+ section refers to the Availability Management Framework and
is not covered in this document.

The above corosync configuration is enough for corosync to operate by itself,
but corosync 1._x_ additionally needs to be told when it is being
used in conjunction with Pacemaker. This can be accomplished
in one of two ways:

* Via the CMAN software provided with Red Hat Enterprise Linux 6 and its derivatives
* Via the pacemaker corosync plugin

To use CMAN, consult its documentation.

To use the pacemaker corosync plugin, add the following fragment to the
corosync configuration and restart the cluster.

.Corosync 1._x_configuration fragment to enable Pacemaker plugin
====
[source,XML]
-------
aisexec {
    user:  root
    group: root
}
service {
    name: pacemaker
    ver: 0
}
-------
====

The cluster needs to be run as root so that its child processes (the
+lrmd+ in particular) have sufficient privileges to perform the
actions requested of it. After all, a cluster manager that can't add
an IP address or start apache is of little use.

The second directive is the one that actually instructs the cluster to
run Pacemaker.

==== Enabling Pacemaker For Heartbeat ====

See the heartbeat documentation for how to set up a +ha.cf+ configuration file.

To enable the use of pacemaker with heartbeat, add the following to a
functional +ha.cf+ configuration file and restart Heartbeat:

.Heartbeat configuration fragment to enable Pacemaker
====
----
crm respawn
----
====
